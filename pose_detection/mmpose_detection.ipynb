{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jRTEc4XEDRBW"
      },
      "outputs": [],
      "source": [
        "!pip install torch==2.1.0\n",
        "!pip install torchvision==0.16.0\n",
        "!pip install torchaudio==2.1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "WLYlYy-44ls_"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "%pip install -U openmim\n",
        "!mim install \"mmengine>=0.7.0\"\n",
        "!mim install \"mmcv==2.1.0\"\n",
        "\n",
        "# Clone mmdetection and mmpose repositories\n",
        "!rm -rf mmdetection\n",
        "!git clone https://github.com/open-mmlab/mmdetection.git -b dev-3.x\n",
        "!git clone https://github.com/open-mmlab/mmpose.git\n",
        "\n",
        "# Install mmdetection\n",
        "%cd mmdetection\n",
        "%pip install -e .\n",
        "!pip install -v -e .\n",
        "!pip install -r requirements.txt\n",
        "%cd ..\n",
        "\n",
        "# Install mmpose\n",
        "%cd mmpose\n",
        "%pip install -e .\n",
        "%cd ..\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bcnios_YFO_q"
      },
      "outputs": [],
      "source": [
        "!mkdir -p demo/mmdetection_cfg\n",
        "!wget https://download.openmmlab.com/mmdetection/v3.0/rtmdet/rtmdet_m_8xb32-300e_coco/rtmdet_m_8xb32-300e_coco_20220719_112220-229f527c.pth -P demo/mmdetection_cfg/\n",
        "\n",
        "!mkdir -p configs/animal_2d_keypoint/topdown_heatmap/animalpose\n",
        "!wget https://download.openmmlab.com/mmpose/animal/hrnet/hrnet_w32_animalpose_256x256-1aa7f075_20210426.pth -P configs/animal_2d_keypoint/topdown_heatmap/animalpose/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "81pIpbr4YQrr"
      },
      "outputs": [],
      "source": [
        "!pip install -U yt-dlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9rr5J9FWYZ4i"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries\n",
        "import yt_dlp as youtube_dl\n",
        "import cv2\n",
        "\n",
        "# Function to download YouTube video\n",
        "def download_youtube_video(url, output_path):\n",
        "    ydl_opts = {'outtmpl': output_path, 'verbose': True, 'ignoreerrors': True}\n",
        "    with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([url])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "CBz-UNH36SgX"
      },
      "outputs": [],
      "source": [
        "# YouTube video URL\n",
        "youtube_url = 'https://youtube.com/shorts/hWlh8JHElmE?si=cucATazqT4u6U7JP'  # Replace with your YouTube video URL\n",
        "video_path = '/content/inferences/video.mp4'  # Specify the full path including the filename (using inference folder here as it is used later on for pose estimation)\n",
        "\n",
        "# Download the YouTube video\n",
        "download_youtube_video(youtube_url, video_path)\n",
        "\n",
        "# Open the video file\n",
        "cap = cv2.VideoCapture(video_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-oGrPgLlWx5B"
      },
      "outputs": [],
      "source": [
        "#Ensure video is saved with video.mp4 in inferences folder before running else rename it\n",
        "!python /content/mmpose/demo/inferencer_demo.py /content/inferences/video.mp4 \\\n",
        "    --pose2d animal --vis-out-dir /content/vis_results --pred-out-dir /content/pred_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0pSp74lpCPp"
      },
      "outputs": [],
      "source": [
        "#add photos in inferences folder and then run this cell , the output folder of processed images will be saved in photo_results\n",
        "!python /content/mmpose/demo/inferencer_demo.py /content/inferences \\\n",
        "    --pose2d animal --vis-out-dir /content/photo_results --pred-out-dir /content/pred_results\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}